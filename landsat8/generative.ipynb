{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Landsat 8 Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/chasedawson/dev/uva_equity_center/climate_equity'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load libraries\n",
    "import json\n",
    "import requests\n",
    "from dotenv import dotenv_values\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "import geopandas as gpd\n",
    "\n",
    "# print cwd\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Methods for working with USGS API ##\n",
    "\n",
    "# API base URL\n",
    "SERVICE_URL = \"https://m2m.cr.usgs.gov/api/api/json/stable/\"\n",
    "\n",
    "def login(username, password):\n",
    "    \"\"\"\n",
    "    Authenticates user given username and password and returns API key.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    username : str, required\n",
    "        USGS account username.\n",
    "        \n",
    "    password : str, required\n",
    "        USGS account password. \n",
    "        \n",
    "    Notes \n",
    "    -----\n",
    "    Go to https://ers.cr.usgs.gov/profile/access to request access \n",
    "    to the API and/or make an account.\n",
    "    \n",
    "    \"\"\"\n",
    "    # login information\n",
    "    payload = {'username': username, 'password': password}\n",
    "\n",
    "    # get apiKey \n",
    "    apiKey = sendRequest(SERVICE_URL + \"login\", payload)\n",
    "    if apiKey == None:\n",
    "        print(\"Login Failed\\n\\n\")\n",
    "    else:\n",
    "        print(\"Login Successful\\n\\n\")\n",
    "    \n",
    "    return apiKey\n",
    "\n",
    "def logout(apiKey):\n",
    "    \"\"\"\n",
    "    Invalidates API key. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    apiKey : str, required\n",
    "        Valid API key. Obtain using the login() method defined above.\n",
    "        \n",
    "    Notes\n",
    "    -----\n",
    "    Make sure to call when you've finished working to ensure that your \n",
    "    API key can't be used by an unauthorized user.\n",
    "    \n",
    "    \"\"\"\n",
    "    endpoint = \"logout\"\n",
    "    if sendRequest(SERVICE_URL + endpoint, None, apiKey) == None:\n",
    "        print(\"Logged Out\\n\\n\")\n",
    "    else:\n",
    "        print(\"Logout Failed\\n\\n\")\n",
    "\n",
    "def sendRequest(url, data, apiKey = None):\n",
    "    \"\"\"\n",
    "    Sends HTTPS request to specified API endpoint. Main method for interacting\n",
    "    with the API.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    url : str, required\n",
    "        API endpoint you wish you access. Typical format is SERVICE_URL + endpoint, \n",
    "        where endpoint might be something like \"login\" or \"data-search.\" See https://m2m.cr.usgs.gov/api/docs/reference/\n",
    "        for all available endpoints.\n",
    "        \n",
    "    data : dict, required\n",
    "        Request payload. Data required changes based on API endpoint. See \n",
    "        https://m2m.cr.usgs.gov/api/docs/reference/ for input parameters, sample requests,\n",
    "        sample and responses for available endpoints.\n",
    "        \n",
    "    apiKey : str, optional (default is None)\n",
    "        Valid API key. Must be speficied for most requests. \"login\" endpoint doesn't \n",
    "        require an API key since you use that endpoint to retrieve a valid API key.\n",
    "    \n",
    "    \"\"\"\n",
    "    json_data = json.dumps(data)\n",
    "    \n",
    "    if apiKey == None:\n",
    "        response = requests.post(url, json_data)\n",
    "    else:\n",
    "        headers = {'X-Auth-Token': apiKey}\n",
    "        response = requests.post(url, json_data, headers = headers)\n",
    "          \n",
    "    try:\n",
    "        httpStatusCode = response.status_code\n",
    "        \n",
    "        if response == None:\n",
    "            print(\"No output from service!\")\n",
    "            sys.exit()\n",
    "            \n",
    "        output = json.loads(response.text)\n",
    "        if output['errorCode'] != None:\n",
    "            print(output['errorCode'], \"- \", output['errorMessage'])\n",
    "            sys.exit()\n",
    "            \n",
    "        if httpStatusCode == 404:\n",
    "            print(\"404 Not Found\")\n",
    "            sys.exit()\n",
    "            \n",
    "        elif httpStatusCode == 401:\n",
    "            print(\"401 Unauthorized\")\n",
    "            sys.exit()\n",
    "            \n",
    "        elif httpStatusCode == 400:\n",
    "            print(\"Error Code\", httpStatusCode)\n",
    "            sys.exit()\n",
    "            \n",
    "    except Exception as e:\n",
    "        response.close()\n",
    "        print(e)\n",
    "        sys.exit()\n",
    "    \n",
    "    response.close()\n",
    "    return output['data']\n",
    "\n",
    "def getFilename_fromCd(cd):\n",
    "    \"\"\"\n",
    "    Uses content-disposition to infer filename and filetype.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    cd : str, required\n",
    "        The Content-Disposition response header from HTTP request \n",
    "        to download a file.\n",
    "        \n",
    "    Output\n",
    "    ------\n",
    "    Inferred filename and type of provided file : str  \n",
    "    \"\"\"\n",
    "    if not cd:\n",
    "        return None\n",
    "    fname = re.findall('filename=(.+)', cd)\n",
    "    if len(fname) == 0:\n",
    "        return None\n",
    "    \n",
    "    return re.sub('\\\"', '', fname[0]) # remove extra quotes\n",
    "\n",
    "def download_file(url):\n",
    "    \"\"\"\n",
    "    Saves file to local system.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "        url: str, required\n",
    "            Link to file to be downloaded.\n",
    "            \n",
    "    Output\n",
    "    ------\n",
    "    Path to downloaded file : str\n",
    "    \"\"\"\n",
    "    res = requests.get(url)\n",
    "    filename = getFilename_fromCd(res.headers.get('content-disposition'))\n",
    "    open(filename, 'wb').write(res.content)\n",
    "    return filename\n",
    "    \n",
    "def search_scenes(apiKey, bounds, start_date, end_date, dataset = \"landsat_ot_c2_l2\", cloud_cover_min = 0, cloud_cover_max = 10):\n",
    "    \"\"\"\n",
    "    Search specified dataset for scenes given spatial and temporal filters.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    apiKey : str, required\n",
    "        Valid API key.\n",
    "        \n",
    "    bounds: dict, required\n",
    "        Dictionary with two entries: 'lowerLeft' and 'upperRight' which contain\n",
    "        the lower left and upper right lat, lng coordinates of the bounding box covering\n",
    "        the area of interest.\n",
    "        \n",
    "    start_date: str, required\n",
    "        Format: YYYY-MM-DD\n",
    "        \n",
    "    end_date: str, required\n",
    "        Format: YYYY-MM-DD\n",
    "        \n",
    "    dataset: str, optional (default is 'landsat_ot_c2_l2')\n",
    "        Dataset alias. Use the 'dataset-search' endpoint to discover\n",
    "        which datasets are available.\n",
    "        \n",
    "    cloud_cover_min : int, optional (default is 0)\n",
    "        Minimum cloud coverage percentage. Scenes with cloud coverage less\n",
    "        than this value will not be included in the result.\n",
    "        \n",
    "    cloud_cover_max: int, optional (default is 10)\n",
    "        \n",
    "    \"\"\"\n",
    "    payload = {\n",
    "        'datasetName': dataset,\n",
    "        'maxResults': 5,\n",
    "        'startingNumber': 1,\n",
    "        'sceneFilter': {\n",
    "            'spatialFilter': {\n",
    "                'filterType': 'mbr',\n",
    "                'lowerLeft': bounds['lowerLeft'],\n",
    "                'upperRight': bounds['upperRight']\n",
    "            },\n",
    "            'acquisitionFilter': {\n",
    "                'start': start_date,\n",
    "                'end': end_date\n",
    "            },\n",
    "            'cloudCoverFilter': {\n",
    "                'max': 10,\n",
    "                'min': 0,\n",
    "                'includeUnknown': False,\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    print(\"Searching Scenes...\")\n",
    "    scenes = sendRequest(SERVICE_URL + \"scene-search\", payload, apiKey)\n",
    "    print(\"Found {num_scenes} Scene(s).\".format(num_scenes = scenes['recordsReturned']))\n",
    "    \n",
    "    return scenes\n",
    "\n",
    "def get_sceneIds(scenes):\n",
    "    \"\"\"\n",
    "    Parses scene data to return list of scene ids.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    scenes : object, required\n",
    "        Output from search_scenes().\n",
    "        \n",
    "    \n",
    "    Output\n",
    "    ------\n",
    "    scene ids : list\n",
    "    \n",
    "    \"\"\"\n",
    "    sceneIds = []\n",
    "    for result in scenes['results']:\n",
    "        sceneIds.append(result['entityId'])\n",
    "    return sceneIds\n",
    "\n",
    "def download_scenes(apiKey, scenes, label, dataset = \"landsat_ot_c2_l2\"):\n",
    "    \"\"\"\n",
    "    Downloads scenes.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    apiKey : str, required\n",
    "        Valid API key.\n",
    "        \n",
    "    scenes : object, required\n",
    "        Scenes you wish to download. Returned from search_scenes().\n",
    "        \n",
    "    label : str, required\n",
    "        Label for your download request.\n",
    "        \n",
    "    dataset : str, optional (default is 'landsat_ot_c2_l2')\n",
    "        Must be the dataset the scenes are from. \n",
    "        \n",
    "    Output\n",
    "    ------\n",
    "    Paths to downloaded files : list\n",
    "    \"\"\"\n",
    "    \n",
    "    sceneIds = get_sceneIds(scenes)\n",
    "    \n",
    "    # download options\n",
    "    payload = {\n",
    "        'datasetName': dataset,\n",
    "        'entityIds': sceneIds,\n",
    "    }\n",
    "    \n",
    "    downloadOptions = sendRequest(SERVICE_URL + \"download-options\", payload, apiKey)\n",
    "    \n",
    "    # aggregate list of available products\n",
    "    downloads = []\n",
    "    for product in downloadOptions:\n",
    "        # make sure the product is available for this scene\n",
    "        if product['available'] == True:\n",
    "            downloads.append({'entityId': product['entityId'],\n",
    "                             'productId': product['id']})\n",
    "            \n",
    "    if downloads:\n",
    "        requestedDownloadsCount = len(downloads)\n",
    "        payload = {\n",
    "            'downloads': downloads,\n",
    "            'label': label\n",
    "        }\n",
    "        requestResults = sendRequest(SERVICE_URL + \"download-request\", payload, apiKey)\n",
    "        if requestResults['preparingDownloads'] != None and len(requestResults['preparingDownloads']) > 0:\n",
    "            payload = {'label': label}\n",
    "            downloadUrls = sendRequest(SERVICE_URL + \"download-retrieve\", payload, apiKey)\n",
    "            downloadIds = []\n",
    "            for download in downloadUrls['available']:\n",
    "                downloadIds.append(download['downloadId'])\n",
    "                \n",
    "            for download in downloadUrls['requested']:\n",
    "                downloadIds.append(download['downloadId'])\n",
    "                \n",
    "            while len(downloadIds) < requestedDownloadsCount:\n",
    "                preparingDownloads = requestedDownloadsCount - len(downloadIds)\n",
    "                print('\\n', preparingDownloads, \"download(s) are not yet available. Waiting for 30 seconds.\\n\")\n",
    "                time.sleep(30)\n",
    "                print(\"Trying to retrieve data.\\n\")\n",
    "                downloadUrls = sendRequest(SERVICE_URL + \"download-retrieve\", payload, apiKey)\n",
    "                for download in downloadUrls['available']:\n",
    "                    if download['downloadId'] not in downloadIds:\n",
    "                        downloadIds.append(download['downloadId'])\n",
    "        else:\n",
    "            # get all available downloads\n",
    "            files = []\n",
    "            for download in requestResults['availableDownloads']:\n",
    "                url = download['url']\n",
    "                filename = download_file(url)\n",
    "                files.append(filename)\n",
    "                \n",
    "            print(\"\\nAll files have been downloaded.\\n\")\n",
    "            return files\n",
    "        \n",
    "    else:\n",
    "        print(\"No available products.\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Successful\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# log in to retrieve API key\n",
    "config = dotenv_values('.env')\n",
    "apiKey = login(config['USGS_USERNAME'], config['USGS_PASSWORD'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = \"landsat_ot_c2_l2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define bounds\n",
    "easternShore_bounds = {'upperRight': {'latitude': 38.08422, 'longitude': -75.07674},\n",
    "                       'lowerLeft': {'latitude': 37.02165, 'longitude': -76.16713}}\n",
    "\n",
    "cville_bounds = {'upperRight': {'latitude': 38.07493, 'longitude': -78.43942},\n",
    "                'lowerLeft': {'latitude': 38.00855, 'longitude': -78.54259}} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define temporal filter start and end constants\n",
    "SUMMER_START = \"2020-06-20\"\n",
    "SUMMER_END = \"2020-09-22\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching Scenes...\n",
      "Found 5 Scene(s).\n",
      "\n",
      "All files have been downloaded.\n",
      "\n",
      "['LC08_L2SP_016034_20200922_20201005_02_T1.tar', 'LC08_L2SP_016034_20200906_20200918_02_T1.tar', 'LC08_L2SP_016034_20200720_20210330_02_T1.tar', 'LC08_L2SP_016033_20200922_20201005_02_T1.tar', 'LC08_L2SP_016033_20200906_20200918_02_T1.tar']\n"
     ]
    }
   ],
   "source": [
    "# get data for Charlottesville\n",
    "cville_scenes = search_scenes(apiKey, cville_bounds, SUMMER_START, SUMMER_END)\n",
    "cville_files = download_scenes(apiKey, cville_scenes, 'cville_summer_2020')\n",
    "print(cville_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching Scenes...\n",
      "Found 5 Scene(s).\n",
      "\n",
      "All files have been downloaded.\n",
      "\n",
      "['LC08_L2SP_015034_20200713_20200912_02_T1.tar', 'LC08_L2SP_015033_20200729_20210330_02_T1.tar', 'LC08_L2SP_014034_20200722_20200911_02_T1.tar', 'LC08_L2SP_013035_20200715_20200912_02_T1.tar', 'LC08_L2SP_013034_20200715_20200912_02_T2.tar']\n"
     ]
    }
   ],
   "source": [
    "easternShore_scenes = search_scenes(apiKey, easternShore_bounds, SUMMER_START, SUMMER_END)\n",
    "easternShore_files = download_scenes(apiKey, easternShore_scenes, 'easternShore_summer_2020')\n",
    "print(easternShore_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logout of API\n",
    "# if successful, apiKey is now invalid\n",
    "logout(apiKey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir landsat8_c2_l2_data\n",
    "!cd landsat8_c2_l2_data\n",
    "!mkdir cville\n",
    "!mkdir easternShore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "\n",
    "def extract_tar(tar, extract_to):\n",
    "    \"\"\"\n",
    "    Extracts tar file to specified location.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    tar : str, required\n",
    "        Path to tar file that will be extracted.\n",
    "        \n",
    "    extract_to : str, required\n",
    "        Path to folder in which the tar file will be extracted.\n",
    "        \n",
    "    Outputs\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    print(\"Extracting\", tar, \"...\")\n",
    "    my_tar = tarfile.open(tar)\n",
    "    my_tar.extractall(extract_to)\n",
    "    my_tar.close()\n",
    "    print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define paths for extracted tar files for both geographic regions\n",
    "# of interest\n",
    "cville_tar_path = \"./landsat8_c2_l2_data/cville\"\n",
    "easternShore_tar_path = \"./landsat8_c2_l2_data/easternShore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting LC08_L2SP_016034_20200922_20201005_02_T1.tar ...\n",
      "Done.\n",
      "Extracting LC08_L2SP_016034_20200906_20200918_02_T1.tar ...\n",
      "Done.\n",
      "Extracting LC08_L2SP_016034_20200720_20210330_02_T1.tar ...\n",
      "Done.\n",
      "Extracting LC08_L2SP_016033_20200922_20201005_02_T1.tar ...\n",
      "Done.\n",
      "Extracting LC08_L2SP_016033_20200906_20200918_02_T1.tar ...\n",
      "Done.\n",
      "Extracting LC08_L2SP_015034_20200713_20200912_02_T1.tar ...\n",
      "Done.\n",
      "Extracting LC08_L2SP_015033_20200729_20210330_02_T1.tar ...\n",
      "Done.\n",
      "Extracting LC08_L2SP_014034_20200722_20200911_02_T1.tar ...\n",
      "Done.\n",
      "Extracting LC08_L2SP_013035_20200715_20200912_02_T1.tar ...\n",
      "Done.\n",
      "Extracting LC08_L2SP_013034_20200715_20200912_02_T2.tar ...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# extract cville files and easternShore files\n",
    "for tar in cville_files:\n",
    "    extract_tar(tar, cville_tar_path)\n",
    "    \n",
    "for tar in easternShore_files:\n",
    "    extract_tar(tar, easternShore_tar_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LC08_L2SP_016033_20200906_20200918_02_T1_ANG.txt\r\n",
      "LC08_L2SP_016033_20200906_20200918_02_T1_MD5.txt\r\n",
      "LC08_L2SP_016033_20200906_20200918_02_T1_MTL.txt\r\n",
      "LC08_L2SP_016033_20200906_20200918_02_T1_MTL.xml\r\n",
      "LC08_L2SP_016033_20200906_20200918_02_T1_QA_PIXEL.TIF\r\n",
      "LC08_L2SP_016033_20200906_20200918_02_T1_QA_RADSAT.TIF\r\n",
      "LC08_L2SP_016033_20200906_20200918_02_T1_SR_B1.TIF\r\n",
      "LC08_L2SP_016033_20200906_20200918_02_T1_SR_B2.TIF\r\n",
      "LC08_L2SP_016033_20200906_20200918_02_T1_SR_B3.TIF\r\n",
      "LC08_L2SP_016033_20200906_20200918_02_T1_SR_B4.TIF\r\n",
      "LC08_L2SP_016033_20200906_20200918_02_T1_SR_B5.TIF\r\n",
      "LC08_L2SP_016033_20200906_20200918_02_T1_SR_B6.TIF\r\n",
      "LC08_L2SP_016033_20200906_20200918_02_T1_SR_B7.TIF\r\n",
      "LC08_L2SP_016033_20200906_20200918_02_T1_SR_QA_AEROSOL.TIF\r\n",
      "LC08_L2SP_016033_20200906_20200918_02_T1_ST_ATRAN.TIF\r\n",
      "LC08_L2SP_016033_20200906_20200918_02_T1_ST_B10.TIF\r\n",
      "LC08_L2SP_016033_20200906_20200918_02_T1_ST_CDIST.TIF\r\n",
      "LC08_L2SP_016033_20200906_20200918_02_T1_ST_DRAD.TIF\r\n",
      "LC08_L2SP_016033_20200906_20200918_02_T1_ST_EMIS.TIF\r\n",
      "LC08_L2SP_016033_20200906_20200918_02_T1_ST_EMSD.TIF\r\n",
      "LC08_L2SP_016033_20200906_20200918_02_T1_ST_QA.TIF\r\n",
      "LC08_L2SP_016033_20200906_20200918_02_T1_ST_TRAD.TIF\r\n",
      "LC08_L2SP_016033_20200906_20200918_02_T1_ST_URAD.TIF\r\n",
      "LC08_L2SP_016033_20200922_20201005_02_T1_ANG.txt\r\n",
      "LC08_L2SP_016033_20200922_20201005_02_T1_MD5.txt\r\n",
      "LC08_L2SP_016033_20200922_20201005_02_T1_MTL.txt\r\n",
      "LC08_L2SP_016033_20200922_20201005_02_T1_MTL.xml\r\n",
      "LC08_L2SP_016033_20200922_20201005_02_T1_QA_PIXEL.TIF\r\n",
      "LC08_L2SP_016033_20200922_20201005_02_T1_QA_RADSAT.TIF\r\n",
      "LC08_L2SP_016033_20200922_20201005_02_T1_SR_B1.TIF\r\n",
      "LC08_L2SP_016033_20200922_20201005_02_T1_SR_B2.TIF\r\n",
      "LC08_L2SP_016033_20200922_20201005_02_T1_SR_B3.TIF\r\n",
      "LC08_L2SP_016033_20200922_20201005_02_T1_SR_B4.TIF\r\n",
      "LC08_L2SP_016033_20200922_20201005_02_T1_SR_B5.TIF\r\n",
      "LC08_L2SP_016033_20200922_20201005_02_T1_SR_B6.TIF\r\n",
      "LC08_L2SP_016033_20200922_20201005_02_T1_SR_B7.TIF\r\n",
      "LC08_L2SP_016033_20200922_20201005_02_T1_SR_QA_AEROSOL.TIF\r\n",
      "LC08_L2SP_016033_20200922_20201005_02_T1_ST_ATRAN.TIF\r\n",
      "LC08_L2SP_016033_20200922_20201005_02_T1_ST_B10.TIF\r\n",
      "LC08_L2SP_016033_20200922_20201005_02_T1_ST_CDIST.TIF\r\n",
      "LC08_L2SP_016033_20200922_20201005_02_T1_ST_DRAD.TIF\r\n",
      "LC08_L2SP_016033_20200922_20201005_02_T1_ST_EMIS.TIF\r\n",
      "LC08_L2SP_016033_20200922_20201005_02_T1_ST_EMSD.TIF\r\n",
      "LC08_L2SP_016033_20200922_20201005_02_T1_ST_QA.TIF\r\n",
      "LC08_L2SP_016033_20200922_20201005_02_T1_ST_TRAD.TIF\r\n",
      "LC08_L2SP_016033_20200922_20201005_02_T1_ST_URAD.TIF\r\n",
      "LC08_L2SP_016034_20200720_20210330_02_T1_ANG.txt\r\n",
      "LC08_L2SP_016034_20200720_20210330_02_T1_MD5.txt\r\n",
      "LC08_L2SP_016034_20200720_20210330_02_T1_MTL.txt\r\n",
      "LC08_L2SP_016034_20200720_20210330_02_T1_MTL.xml\r\n",
      "LC08_L2SP_016034_20200720_20210330_02_T1_QA_PIXEL.TIF\r\n",
      "LC08_L2SP_016034_20200720_20210330_02_T1_QA_RADSAT.TIF\r\n",
      "LC08_L2SP_016034_20200720_20210330_02_T1_SR_B1.TIF\r\n",
      "LC08_L2SP_016034_20200720_20210330_02_T1_SR_B2.TIF\r\n",
      "LC08_L2SP_016034_20200720_20210330_02_T1_SR_B3.TIF\r\n",
      "LC08_L2SP_016034_20200720_20210330_02_T1_SR_B4.TIF\r\n",
      "LC08_L2SP_016034_20200720_20210330_02_T1_SR_B5.TIF\r\n",
      "LC08_L2SP_016034_20200720_20210330_02_T1_SR_B6.TIF\r\n",
      "LC08_L2SP_016034_20200720_20210330_02_T1_SR_B7.TIF\r\n",
      "LC08_L2SP_016034_20200720_20210330_02_T1_SR_QA_AEROSOL.TIF\r\n",
      "LC08_L2SP_016034_20200720_20210330_02_T1_ST_ATRAN.TIF\r\n",
      "LC08_L2SP_016034_20200720_20210330_02_T1_ST_B10.TIF\r\n",
      "LC08_L2SP_016034_20200720_20210330_02_T1_ST_CDIST.TIF\r\n",
      "LC08_L2SP_016034_20200720_20210330_02_T1_ST_DRAD.TIF\r\n",
      "LC08_L2SP_016034_20200720_20210330_02_T1_ST_EMIS.TIF\r\n",
      "LC08_L2SP_016034_20200720_20210330_02_T1_ST_EMSD.TIF\r\n",
      "LC08_L2SP_016034_20200720_20210330_02_T1_ST_QA.TIF\r\n",
      "LC08_L2SP_016034_20200720_20210330_02_T1_ST_TRAD.TIF\r\n",
      "LC08_L2SP_016034_20200720_20210330_02_T1_ST_URAD.TIF\r\n",
      "LC08_L2SP_016034_20200906_20200918_02_T1_ANG.txt\r\n",
      "LC08_L2SP_016034_20200906_20200918_02_T1_MD5.txt\r\n",
      "LC08_L2SP_016034_20200906_20200918_02_T1_MTL.txt\r\n",
      "LC08_L2SP_016034_20200906_20200918_02_T1_MTL.xml\r\n",
      "LC08_L2SP_016034_20200906_20200918_02_T1_QA_PIXEL.TIF\r\n",
      "LC08_L2SP_016034_20200906_20200918_02_T1_QA_RADSAT.TIF\r\n",
      "LC08_L2SP_016034_20200906_20200918_02_T1_SR_B1.TIF\r\n",
      "LC08_L2SP_016034_20200906_20200918_02_T1_SR_B2.TIF\r\n",
      "LC08_L2SP_016034_20200906_20200918_02_T1_SR_B3.TIF\r\n",
      "LC08_L2SP_016034_20200906_20200918_02_T1_SR_B4.TIF\r\n",
      "LC08_L2SP_016034_20200906_20200918_02_T1_SR_B5.TIF\r\n",
      "LC08_L2SP_016034_20200906_20200918_02_T1_SR_B6.TIF\r\n",
      "LC08_L2SP_016034_20200906_20200918_02_T1_SR_B7.TIF\r\n",
      "LC08_L2SP_016034_20200906_20200918_02_T1_SR_QA_AEROSOL.TIF\r\n",
      "LC08_L2SP_016034_20200906_20200918_02_T1_ST_ATRAN.TIF\r\n",
      "LC08_L2SP_016034_20200906_20200918_02_T1_ST_B10.TIF\r\n",
      "LC08_L2SP_016034_20200906_20200918_02_T1_ST_CDIST.TIF\r\n",
      "LC08_L2SP_016034_20200906_20200918_02_T1_ST_DRAD.TIF\r\n",
      "LC08_L2SP_016034_20200906_20200918_02_T1_ST_EMIS.TIF\r\n",
      "LC08_L2SP_016034_20200906_20200918_02_T1_ST_EMSD.TIF\r\n",
      "LC08_L2SP_016034_20200906_20200918_02_T1_ST_QA.TIF\r\n",
      "LC08_L2SP_016034_20200906_20200918_02_T1_ST_TRAD.TIF\r\n",
      "LC08_L2SP_016034_20200906_20200918_02_T1_ST_URAD.TIF\r\n",
      "LC08_L2SP_016034_20200922_20201005_02_T1_ANG.txt\r\n",
      "LC08_L2SP_016034_20200922_20201005_02_T1_MD5.txt\r\n",
      "LC08_L2SP_016034_20200922_20201005_02_T1_MTL.txt\r\n",
      "LC08_L2SP_016034_20200922_20201005_02_T1_MTL.xml\r\n",
      "LC08_L2SP_016034_20200922_20201005_02_T1_QA_PIXEL.TIF\r\n",
      "LC08_L2SP_016034_20200922_20201005_02_T1_QA_RADSAT.TIF\r\n",
      "LC08_L2SP_016034_20200922_20201005_02_T1_SR_B1.TIF\r\n",
      "LC08_L2SP_016034_20200922_20201005_02_T1_SR_B2.TIF\r\n",
      "LC08_L2SP_016034_20200922_20201005_02_T1_SR_B3.TIF\r\n",
      "LC08_L2SP_016034_20200922_20201005_02_T1_SR_B4.TIF\r\n",
      "LC08_L2SP_016034_20200922_20201005_02_T1_SR_B5.TIF\r\n",
      "LC08_L2SP_016034_20200922_20201005_02_T1_SR_B6.TIF\r\n",
      "LC08_L2SP_016034_20200922_20201005_02_T1_SR_B7.TIF\r\n",
      "LC08_L2SP_016034_20200922_20201005_02_T1_SR_QA_AEROSOL.TIF\r\n",
      "LC08_L2SP_016034_20200922_20201005_02_T1_ST_ATRAN.TIF\r\n",
      "LC08_L2SP_016034_20200922_20201005_02_T1_ST_B10.TIF\r\n",
      "LC08_L2SP_016034_20200922_20201005_02_T1_ST_CDIST.TIF\r\n",
      "LC08_L2SP_016034_20200922_20201005_02_T1_ST_DRAD.TIF\r\n",
      "LC08_L2SP_016034_20200922_20201005_02_T1_ST_EMIS.TIF\r\n",
      "LC08_L2SP_016034_20200922_20201005_02_T1_ST_EMSD.TIF\r\n",
      "LC08_L2SP_016034_20200922_20201005_02_T1_ST_QA.TIF\r\n",
      "LC08_L2SP_016034_20200922_20201005_02_T1_ST_TRAD.TIF\r\n",
      "LC08_L2SP_016034_20200922_20201005_02_T1_ST_URAD.TIF\r\n"
     ]
    }
   ],
   "source": [
    "# verify that cville data has been extracted\n",
    "! ls landsat8_c2_l2_data/cville"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LC08_L2SP_013034_20200715_20200912_02_T2_ANG.txt\r\n",
      "LC08_L2SP_013034_20200715_20200912_02_T2_MD5.txt\r\n",
      "LC08_L2SP_013034_20200715_20200912_02_T2_MTL.txt\r\n",
      "LC08_L2SP_013034_20200715_20200912_02_T2_MTL.xml\r\n",
      "LC08_L2SP_013034_20200715_20200912_02_T2_QA_PIXEL.TIF\r\n",
      "LC08_L2SP_013034_20200715_20200912_02_T2_QA_RADSAT.TIF\r\n",
      "LC08_L2SP_013034_20200715_20200912_02_T2_SR_B1.TIF\r\n",
      "LC08_L2SP_013034_20200715_20200912_02_T2_SR_B2.TIF\r\n",
      "LC08_L2SP_013034_20200715_20200912_02_T2_SR_B3.TIF\r\n",
      "LC08_L2SP_013034_20200715_20200912_02_T2_SR_B4.TIF\r\n",
      "LC08_L2SP_013034_20200715_20200912_02_T2_SR_B5.TIF\r\n",
      "LC08_L2SP_013034_20200715_20200912_02_T2_SR_B6.TIF\r\n",
      "LC08_L2SP_013034_20200715_20200912_02_T2_SR_B7.TIF\r\n",
      "LC08_L2SP_013034_20200715_20200912_02_T2_SR_QA_AEROSOL.TIF\r\n",
      "LC08_L2SP_013034_20200715_20200912_02_T2_ST_ATRAN.TIF\r\n",
      "LC08_L2SP_013034_20200715_20200912_02_T2_ST_B10.TIF\r\n",
      "LC08_L2SP_013034_20200715_20200912_02_T2_ST_CDIST.TIF\r\n",
      "LC08_L2SP_013034_20200715_20200912_02_T2_ST_DRAD.TIF\r\n",
      "LC08_L2SP_013034_20200715_20200912_02_T2_ST_EMIS.TIF\r\n",
      "LC08_L2SP_013034_20200715_20200912_02_T2_ST_EMSD.TIF\r\n",
      "LC08_L2SP_013034_20200715_20200912_02_T2_ST_QA.TIF\r\n",
      "LC08_L2SP_013034_20200715_20200912_02_T2_ST_TRAD.TIF\r\n",
      "LC08_L2SP_013034_20200715_20200912_02_T2_ST_URAD.TIF\r\n",
      "LC08_L2SP_013035_20200715_20200912_02_T1_ANG.txt\r\n",
      "LC08_L2SP_013035_20200715_20200912_02_T1_MD5.txt\r\n",
      "LC08_L2SP_013035_20200715_20200912_02_T1_MTL.txt\r\n",
      "LC08_L2SP_013035_20200715_20200912_02_T1_MTL.xml\r\n",
      "LC08_L2SP_013035_20200715_20200912_02_T1_QA_PIXEL.TIF\r\n",
      "LC08_L2SP_013035_20200715_20200912_02_T1_QA_RADSAT.TIF\r\n",
      "LC08_L2SP_013035_20200715_20200912_02_T1_SR_B1.TIF\r\n",
      "LC08_L2SP_013035_20200715_20200912_02_T1_SR_B2.TIF\r\n",
      "LC08_L2SP_013035_20200715_20200912_02_T1_SR_B3.TIF\r\n",
      "LC08_L2SP_013035_20200715_20200912_02_T1_SR_B4.TIF\r\n",
      "LC08_L2SP_013035_20200715_20200912_02_T1_SR_B5.TIF\r\n",
      "LC08_L2SP_013035_20200715_20200912_02_T1_SR_B6.TIF\r\n",
      "LC08_L2SP_013035_20200715_20200912_02_T1_SR_B7.TIF\r\n",
      "LC08_L2SP_013035_20200715_20200912_02_T1_SR_QA_AEROSOL.TIF\r\n",
      "LC08_L2SP_013035_20200715_20200912_02_T1_ST_ATRAN.TIF\r\n",
      "LC08_L2SP_013035_20200715_20200912_02_T1_ST_B10.TIF\r\n",
      "LC08_L2SP_013035_20200715_20200912_02_T1_ST_CDIST.TIF\r\n",
      "LC08_L2SP_013035_20200715_20200912_02_T1_ST_DRAD.TIF\r\n",
      "LC08_L2SP_013035_20200715_20200912_02_T1_ST_EMIS.TIF\r\n",
      "LC08_L2SP_013035_20200715_20200912_02_T1_ST_EMSD.TIF\r\n",
      "LC08_L2SP_013035_20200715_20200912_02_T1_ST_QA.TIF\r\n",
      "LC08_L2SP_013035_20200715_20200912_02_T1_ST_TRAD.TIF\r\n",
      "LC08_L2SP_013035_20200715_20200912_02_T1_ST_URAD.TIF\r\n",
      "LC08_L2SP_014034_20200722_20200911_02_T1_ANG.txt\r\n",
      "LC08_L2SP_014034_20200722_20200911_02_T1_MD5.txt\r\n",
      "LC08_L2SP_014034_20200722_20200911_02_T1_MTL.txt\r\n",
      "LC08_L2SP_014034_20200722_20200911_02_T1_MTL.xml\r\n",
      "LC08_L2SP_014034_20200722_20200911_02_T1_QA_PIXEL.TIF\r\n",
      "LC08_L2SP_014034_20200722_20200911_02_T1_QA_RADSAT.TIF\r\n",
      "LC08_L2SP_014034_20200722_20200911_02_T1_SR_B1.TIF\r\n",
      "LC08_L2SP_014034_20200722_20200911_02_T1_SR_B2.TIF\r\n",
      "LC08_L2SP_014034_20200722_20200911_02_T1_SR_B3.TIF\r\n",
      "LC08_L2SP_014034_20200722_20200911_02_T1_SR_B4.TIF\r\n",
      "LC08_L2SP_014034_20200722_20200911_02_T1_SR_B5.TIF\r\n",
      "LC08_L2SP_014034_20200722_20200911_02_T1_SR_B6.TIF\r\n",
      "LC08_L2SP_014034_20200722_20200911_02_T1_SR_B7.TIF\r\n",
      "LC08_L2SP_014034_20200722_20200911_02_T1_SR_QA_AEROSOL.TIF\r\n",
      "LC08_L2SP_014034_20200722_20200911_02_T1_ST_ATRAN.TIF\r\n",
      "LC08_L2SP_014034_20200722_20200911_02_T1_ST_B10.TIF\r\n",
      "LC08_L2SP_014034_20200722_20200911_02_T1_ST_CDIST.TIF\r\n",
      "LC08_L2SP_014034_20200722_20200911_02_T1_ST_DRAD.TIF\r\n",
      "LC08_L2SP_014034_20200722_20200911_02_T1_ST_EMIS.TIF\r\n",
      "LC08_L2SP_014034_20200722_20200911_02_T1_ST_EMSD.TIF\r\n",
      "LC08_L2SP_014034_20200722_20200911_02_T1_ST_QA.TIF\r\n",
      "LC08_L2SP_014034_20200722_20200911_02_T1_ST_TRAD.TIF\r\n",
      "LC08_L2SP_014034_20200722_20200911_02_T1_ST_URAD.TIF\r\n",
      "LC08_L2SP_015033_20200729_20210330_02_T1_ANG.txt\r\n",
      "LC08_L2SP_015033_20200729_20210330_02_T1_MD5.txt\r\n",
      "LC08_L2SP_015033_20200729_20210330_02_T1_MTL.txt\r\n",
      "LC08_L2SP_015033_20200729_20210330_02_T1_MTL.xml\r\n",
      "LC08_L2SP_015033_20200729_20210330_02_T1_QA_PIXEL.TIF\r\n",
      "LC08_L2SP_015033_20200729_20210330_02_T1_QA_RADSAT.TIF\r\n",
      "LC08_L2SP_015033_20200729_20210330_02_T1_SR_B1.TIF\r\n",
      "LC08_L2SP_015033_20200729_20210330_02_T1_SR_B2.TIF\r\n",
      "LC08_L2SP_015033_20200729_20210330_02_T1_SR_B3.TIF\r\n",
      "LC08_L2SP_015033_20200729_20210330_02_T1_SR_B4.TIF\r\n",
      "LC08_L2SP_015033_20200729_20210330_02_T1_SR_B5.TIF\r\n",
      "LC08_L2SP_015033_20200729_20210330_02_T1_SR_B6.TIF\r\n",
      "LC08_L2SP_015033_20200729_20210330_02_T1_SR_B7.TIF\r\n",
      "LC08_L2SP_015033_20200729_20210330_02_T1_SR_QA_AEROSOL.TIF\r\n",
      "LC08_L2SP_015033_20200729_20210330_02_T1_ST_ATRAN.TIF\r\n",
      "LC08_L2SP_015033_20200729_20210330_02_T1_ST_B10.TIF\r\n",
      "LC08_L2SP_015033_20200729_20210330_02_T1_ST_CDIST.TIF\r\n",
      "LC08_L2SP_015033_20200729_20210330_02_T1_ST_DRAD.TIF\r\n",
      "LC08_L2SP_015033_20200729_20210330_02_T1_ST_EMIS.TIF\r\n",
      "LC08_L2SP_015033_20200729_20210330_02_T1_ST_EMSD.TIF\r\n",
      "LC08_L2SP_015033_20200729_20210330_02_T1_ST_QA.TIF\r\n",
      "LC08_L2SP_015033_20200729_20210330_02_T1_ST_TRAD.TIF\r\n",
      "LC08_L2SP_015033_20200729_20210330_02_T1_ST_URAD.TIF\r\n",
      "LC08_L2SP_015034_20200713_20200912_02_T1_ANG.txt\r\n",
      "LC08_L2SP_015034_20200713_20200912_02_T1_MD5.txt\r\n",
      "LC08_L2SP_015034_20200713_20200912_02_T1_MTL.txt\r\n",
      "LC08_L2SP_015034_20200713_20200912_02_T1_MTL.xml\r\n",
      "LC08_L2SP_015034_20200713_20200912_02_T1_QA_PIXEL.TIF\r\n",
      "LC08_L2SP_015034_20200713_20200912_02_T1_QA_RADSAT.TIF\r\n",
      "LC08_L2SP_015034_20200713_20200912_02_T1_SR_B1.TIF\r\n",
      "LC08_L2SP_015034_20200713_20200912_02_T1_SR_B2.TIF\r\n",
      "LC08_L2SP_015034_20200713_20200912_02_T1_SR_B3.TIF\r\n",
      "LC08_L2SP_015034_20200713_20200912_02_T1_SR_B4.TIF\r\n",
      "LC08_L2SP_015034_20200713_20200912_02_T1_SR_B5.TIF\r\n",
      "LC08_L2SP_015034_20200713_20200912_02_T1_SR_B6.TIF\r\n",
      "LC08_L2SP_015034_20200713_20200912_02_T1_SR_B7.TIF\r\n",
      "LC08_L2SP_015034_20200713_20200912_02_T1_SR_QA_AEROSOL.TIF\r\n",
      "LC08_L2SP_015034_20200713_20200912_02_T1_ST_ATRAN.TIF\r\n",
      "LC08_L2SP_015034_20200713_20200912_02_T1_ST_B10.TIF\r\n",
      "LC08_L2SP_015034_20200713_20200912_02_T1_ST_CDIST.TIF\r\n",
      "LC08_L2SP_015034_20200713_20200912_02_T1_ST_DRAD.TIF\r\n",
      "LC08_L2SP_015034_20200713_20200912_02_T1_ST_EMIS.TIF\r\n",
      "LC08_L2SP_015034_20200713_20200912_02_T1_ST_EMSD.TIF\r\n",
      "LC08_L2SP_015034_20200713_20200912_02_T1_ST_QA.TIF\r\n",
      "LC08_L2SP_015034_20200713_20200912_02_T1_ST_TRAD.TIF\r\n",
      "LC08_L2SP_015034_20200713_20200912_02_T1_ST_URAD.TIF\r\n"
     ]
    }
   ],
   "source": [
    "# verify that easternShore data has been extracted\n",
    "! ls landsat8_c2_l2_data/easternShore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete original tar files\n",
    "for tar in cville_files:\n",
    "    os.remove(tar)\n",
    "    \n",
    "for tar in easternShore_files:\n",
    "    os.remove(tar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_tar_endings(files):\n",
    "    \"\"\"\n",
    "    Removes .tar endings from a list of filenames.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    files : list, required\n",
    "        List of tar filenames.\n",
    "        \n",
    "    Output\n",
    "    ------\n",
    "    list of filenames with .tar endings removed : list\n",
    "    \n",
    "    \"\"\"\n",
    "    reformatted_names = []\n",
    "    for file in files:\n",
    "        reformatted_names.append(file.split('.')[0])\n",
    "    return reformatted_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove .tar endings\n",
    "cville_files = remove_tar_endings(cville_files)\n",
    "easternShore_files = remove_tar_endings(easternShore_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Spatial Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyreadr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_RDS(rds_file):\n",
    "    \"\"\"\n",
    "    Reads RDS file and outputs pandas DataFrame.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    rds_file : str, required\n",
    "        Path to RDS file that will be read.\n",
    "    \"\"\"\n",
    "    print(\"Reading\", rds_file, \"...\")\n",
    "    result = pyreadr.read_r(rds_file)\n",
    "    return result[None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/chasedawson/dev/uva_equity_center/spatial_units/data'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change working directory\n",
    "os.chdir(\"../spatial_units/data\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading cville_counties.RDS ...\n"
     ]
    },
    {
     "ename": "LibrdataError",
     "evalue": "Invalid file, or file has unsupported features",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLibrdataError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-d7f06e3b2546>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcville_counties\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_RDS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cville_counties.RDS\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-48-ba08cdb301bf>\u001b[0m in \u001b[0;36mread_RDS\u001b[0;34m(rds_file)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \"\"\"\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Reading\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrds_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyreadr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_r\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrds_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/earth-analytics-python/lib/python3.8/site-packages/pyreadr/pyreadr.py\u001b[0m in \u001b[0;36mread_r\u001b[0;34m(path, use_objects, timezone)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mPyreadrError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File {0} does not exist!\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/earth-analytics-python/lib/python3.8/site-packages/pyreadr/librdata.pyx\u001b[0m in \u001b[0;36mpyreadr.librdata.Parser.parse\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/earth-analytics-python/lib/python3.8/site-packages/pyreadr/librdata.pyx\u001b[0m in \u001b[0;36mpyreadr.librdata.Parser.parse\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mLibrdataError\u001b[0m: Invalid file, or file has unsupported features"
     ]
    }
   ],
   "source": [
    "cville_counties = read_RDS(\"cville_counties.RDS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clip Raster Data with Shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from shapely.geometry import mapping\n",
    "import rioxarray as rxr\n",
    "import xarray as xr\n",
    "import earthpy as et\n",
    "import earthpy.plot as ep\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename ending for raster temperature data\n",
    "ST_ENDING = \"_ST_B10.TIF\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# 2. clip raster images by shp files of cville city and counties in eastern shore\n",
    "# 3. compute zonal raster statistics for areas of interest: county level, block level, tract level etc\n",
    "# 4. save these stats in csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# References\n",
    "# [Downloading Files From Web Using Python](https://www.tutorialspoint.com/downloading-files-from-web-using-python)\n",
    "# [Jupyter Tips and Tricks](https://chrieke.medium.com/jupyter-tips-and-tricks-994fdddb2057)\n",
    "# [USGS/EROS Inventory Service Documentation (Machine-to-Machine) API](https://m2m.cr.usgs.gov/api/docs/json/#section-overview)\n",
    "# [How are files extracted from a tar file using Python?](https://www.tutorialspoint.com/How-are-files-extracted-from-a-tar-file-using-Python)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "earth-analytics-python",
   "language": "python",
   "name": "earth-analytics-python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
